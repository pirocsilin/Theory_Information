<!DOCTYPE html>
<html lang="en">

<head>

  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="description" content="">
  <meta name="author" content="do.sibsutis.ru">

  <title>Тема 1. Конспект лекций</title>
	
	<link rel="icon" type="image/png" href="../lib/css/favicon.png">
  <!-- Bootstrap Core CSS -->
  <link href="../lib/css/bootstrap.css" rel="stylesheet">
	
  <!-- Custom CSS -->
  <link href="../lib/css/scrolling-nav.css" rel="stylesheet">

  <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
  <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
  <!--[if lt IE 9]>
    <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
    <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
  <![endif]-->
</head>

<!-- The #page-top ID is part of the scrolling feature - the data-spy and data-target are part of the built-in Bootstrap scrollspy function -->

<body id="page-top" data-spy="scroll" data-target=".navbar-fixed-top">
  <!-- Navigation -->
<nav class="navbar navbar-default navbar-fixed-top">
 <div class="container">
  <!-- Brand and toggle get grouped for better mobile display -->
  <div class="navbar-header">
   <li class="hidden"> <a class="page-scroll" href="#page-top"></a> </li>
	 
	 <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1" aria-expanded="false">
    <span class="icon-bar"></span>
    <span class="icon-bar"></span>
    <span class="icon-bar"></span>
   </button>
	 
   <a class="navbar-brand " href="../index.htm"> 
  <text class = "hidden-xs">Теория информации</text> 
  <text class = "visible-xs">ТИ</text>
	 </a>
  </div>

  <!-- Collect the nav links, forms, and glyphicon glyphicon-list-alt content for toggling -->
  <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
   
	 <!-- <ul class="nav navbar-nav">
		<li><a href="#"></a></li> 
   </ul> -->
	
   <ul class="nav navbar-nav navbar-right">
    <li class="dropdown">
		<button type="button" class="navbar-toggle dropdown-toggle hidden-xs" data-toggle="dropdown" role="button" aria-haspopup="true" aria-expanded="false">
			<span class="icon-bar"></span>
			<span class="icon-bar"></span>
			<span class="icon-bar"></span>
		</button>	   
		<a class = "dropdown-toggle visible-xs" data-toggle="dropdown" role="button" aria-haspopup="true" aria-expanded="false">Материалы</a>
     <ul class="dropdown-menu">
    <li><a href="../index.htm">Аннотация курса</a></li>
      <li role="separator" class="divider"></li>
  
   <li><a href="lec_index.htm">Теория</a></li>
   
<li><a href="labs.htm">Лабораторные работы</a></li> 
<li><a href="c_work.htm">Контрольная работа</a></li>
      <li role="separator" class="divider"></li>
    
      <li><a href="lit.htm">Литература</a></li>
      <!--li><a href="q.htm">Вопросы для самопроверки</a></li-->			
     </ul>
 </li>
 </ul>
  </div><!-- /.navbar-collapse -->
 </div><!-- /.container-fluid -->
</nav>


  <div id="intro" class="section content-section ">
    <div class="container">
       <div class="row">
        <div class="col-lg-12">	


<!-- содержание -->	
<div class="page-header">				
<h3>1. Введение</h3>


</div>
<!--начало-->
<p>До середины ХХ века под  информацией понимали  только передачу  сведений от одного человека другому человеку или группе людей с помощью устной  или письменной речи, передачу условных знаков (символов) посредством специальных  передающих устройств. Наскальные рисунки первобытных людей, передача световых  сигналов, чтение книг – все это примеры выполнения операций по хранению,  передаче и переработке информации.</p>
<p> Однако лишь к середине  ХХ века информация стала предметом научного  исследования. Начало развитию <em>теории  информации</em> как научной дисциплины было положено в 1949 г. после публикации  статьи «Математическая теория связи» К. Шеннона и У. Уивера, которые предложили  количественную меру информации и заложили фундамент для дальнейших исследований  в этой области.</p>
<p>Теория информации тесно  связана с такими разделами математики как теория вероятностей и математическая  статистика. С другой стороны теория информации представляет собой  математический фундамент для теории связи. Таким образом, теория информации  – это математическая теория, которая изучает  процессы хранения, преобразования и передачи информации по каналам связи.</p>
<p>Под <em>информацией</em> нужно понимать совокупность упорядоченных данных о каких-либо событиях, процессах, явлениях и т.п., рассматриваемых в  аспекте их передачи в пространстве и во времени.</p>
<p>Существует  несколько взглядов на сущность информации, однако большинство специалистов  считает, что существует информация двух типов:</p>
<ul>
  <li>Информация <em>техническая</em>, которая передается по  каналам связи и отображается на экранах дисплеев. Количество такой информации  может быть точно вычислено, и процессы, происходящие с такой информацией,  поддаются строгому анализу. </li>
  <li>Информация <em>семантическая</em>, т.е. <em>смысловая</em>. Такого типа информация содержится, например, в  литературном или музыкальном произведении. Хотя для анализа такой информации и  предлагаются различные математические модели, количественные оценки на их  основе весьма условны и приблизительны.  </li>
</ul>
<p>Современная теория  информация исходит из представления о том, что информация (которая обычно, но  не обязательно имеет смысл), предназначенная для хранения или передачи по  каналу связи не известна заранее с полной определенностью. Заранее известно  лишь множество, из которого могут быть выбраны информационные сообщения,  и возможно частота появления этих сообщений  (т.е. вероятность сообщений). Такая «неопределенность» информационных сообщений  допускает количественное выражение, что и определяет возможность хранения и  передачи информации.</p>
<p>Основной моделью, которую  изучает теория информации, является <em>модель  системы передачи сигналов:</em></p>
<p>&nbsp;</p>
<p><img src="img/vvedenie_clip_image001.gif" alt="" width="547" height="184"><em>&nbsp;</em></p>
<p><em>&nbsp;</em></p>
<p>Рисунок 1 Модель системы передачи сигналов </p>
<br>
<p>Начальным звеномв приведенной выше модели является<em> источник информации.</em> В курсе будут  рассматриваться <em>дискретные источники без  памяти</em>, в которых <em>выходом</em> является  последовательность символов некоторого фиксированного алфавита или <em>сообщения</em>. Множество всех различных  символов, порождаемых некоторым источником, называется <em>алфавитом источника</em>, а количество символов в этом множестве – <em>размером алфавита источника</em>. Например,  можно считать, что текст на русском языке порождается источником с алфавитом из  33 русских букв, пробела и знаков препинания.</p>
<p>Далее для передачи по каналу  связи информация подвергается <em>кодированию</em>.  <em>Кодирование</em> – это способ представления информации в удобном для хранения и передачи виде. В  связи с развитием информационных технологий кодирование является центральным  вопросом при решении самых разных задач программирования, таких как:</p>
<ul>
  <li>представление данных произвольной структуры (числа, текст, графика) в  памяти компьютера;</li>
  <li>обеспечение помехоустойчивости при передаче данных по каналам связи;</li>
  <li>сжатие информации в базах данных.</li>
</ul>
<p><em>Кодирование дискретного источника</em> заключается в сопоставлении символов  алфавита <em>А</em> источника символам или группам  символов алфавита <em>В</em> (которые  называются <em>кодовыми словами</em>). Алфавит <em>В </em>называется <em>кодовым алфавитом</em>. <em>Кодом</em> называется совокупность всех кодовых слов, применяемых для представления порождаемых  источником символов. Обратная процедура сопоставления кодовым словам алфавита <em>В</em> символов алфавита <em>А </em>называется <em>декодированием</em>.</p>
<p>Разработка и исследование  эффективных конструкций кодирования информации   являются одними из основных задач теории информации.</p>
<p><strong>Пример</strong>. Азбука Морзе является  общеизвестным кодом из символов телеграфного алфавита, в котором буквам  русского языка соответствуют кодовые слова (последовательности) из «точек» и «тире».</p>
<p>&nbsp;</p>
<p><img src="img/2.png" alt="" width="654" height="483"></p>
<p>&nbsp;</p>
<p>При передаче закодированного  сообщения по каналу связи могут возникать помехи (или шум), которые искажают  сообщение, так что при декодировании приемник может получить изменённое  сообщение. Для защиты сообщения от помех при передаче по каналу связи  существуют специальные методы помехоустойчивого кодирования.</p>
<p> Далее будет рассматриваться  только <em>двоичное кодирование</em>, т.е.  размер кодового алфавита равен 2. Конечную последовательность битов (0 или 1)  назовем <em>кодовым словом</em>, а количество  битов в этой последовательности – <em>длиной  кодового слова</em>.</p>
<p><strong>Пример 1.1</strong>. Код ASCII (американский  стандартный код для обмена информацией) каждому символу ставит в однозначное  соответствие кодовое слово длиной 8 бит.</p>
<p>Известны <em>два класса методов кодирования</em> дискретного источника информации: равномерное и неравномерное кодирование. Под<em> равномерным кодированием</em> понимается  использование кодов со словами постоянной длины. Для того чтобы декодирование  равномерного кода было возможным, разным символам алфавита источника должны  соответствовать разные кодовые слова. При этом длина кодового слова должна быть  не меньше <img src="img/3.png" alt="" width="81" height="31" align="absmiddle"> символов, где <em>m</em> – размер исходного алфавита, <em>n</em> – размер кодового алфавита.</p>
<p>&nbsp;</p>
<p><strong>Пример 1.2</strong>. Для кодирования источника, порождающего 26 букв латинского алфавита,  равномерным двоичным кодом требуется построить кодовые слова длиной не  меньше <img src="img/4.png" alt="" width="156" height="31" align="absmiddle">.</p>
<p>При<em> неравномерном кодировании источника</em> используются кодовые слова  разной длины. Причем кодовые слова обычно строятся так, чтобы часто встречающиеся  символы кодировались более короткими кодовыми словами, а редкие символы –  более длинными (за счет этого и достигается «сжатие» данных).</p>
<p>Под<em> сжатием данных</em> понимается <em>компактное  представление данных</em>, достигаемое за счет избыточности информации,  содержащейся в сообщениях. Большое значение для практического использования  имеет <em>неискажающее сжатие</em>,  позволяющее полностью восстановить исходное сообщение. При<em> неискажающем сжатии</em> происходит кодирование сообщения перед началом  передачи или хранения, а после окончания процесса сообщение однозначно  декодируется (это соответствует модели канала без шума (помех)).</p>
<p><em>Методы сжатия  данных</em> можно разделить на две группы:  статические методы и адаптивные методы. <em>Статические</em> методы сжатия данных предназначены для кодирования конкретных источников  информации с известной статистической структурой,  порождающих определенное множество сообщений. Эти методы базируются на знании  статистической структуры исходных данных. К наиболее известным статическим  методам сжатия относятся коды Хаффмана, Шеннона, Фано, Гилберта-Мура,  арифметический код и другие методы, которые используют известные сведения о  вероятностях порождения источником различных символов или их сочетаний.</p>
<p>Если статистика источника информации неизвестна или  изменяется с течением времени, то для кодирования сообщений такого источника  применяются <em>адаптивные методы сжатия</em>.  В <em>адаптивных</em> методах при кодировании  очередного символа текста используются сведения о ранее закодированной части  сообщения для оценки вероятности появления очередного символа. В процессе  кодирования адаптивные методы «настраиваются» на статистическую структуру  кодируемых сообщений, т.е. коды символов меняются в зависимости от накопленной  статистики данных. Это позволяет адаптивным методам эффективно и быстро  кодировать сообщение за один просмотр.</p>
<p>Существует множество  различных адаптивных методов сжатия данных. Наиболее известные из них –  адаптивный код Хаффмана, код «стопка  книг», интервальный и частотный коды, а также методы из класса Лемпела-Зива.</p>
<br><br>
<!--конец-->
      
				

				</div>
			</div>
			
      </div>
    </div>
  </div>
	
	<!--Меню навигации по Темам -->	
	<div aria-label="..." class = "nav-menu">
	 <ul class="pager background-transition-slow">
		 <li title="Наверх" style = "margin-right:15px;	"><a class = "glyphicon glyphicon-menu-up page-scroll" href="#page-top"></a></li>
		 <li title="К предыдущей лекции"><a class = "glyphicon glyphicon-menu-left page-scroll" href="lec_index.htm"></a></li>
		 <li title="В содержание"><a class = "glyphicon glyphicon-list-alt" href="lec_index.htm"></a></li>
		 <li title="К следующей лекции"><a class = "glyphicon glyphicon-menu-right page-scroll" href="gl2.htm"></a></li>
	 </ul>
	</div>
	<!---->
	
	</div>
  <!-- jQuery -->
  <script src="../lib/js/jquery.js"></script>

  <!-- Bootstrap Core JavaScript -->
  <script src="../lib/js/bootstrap.min.js"></script>

  <!-- Scrolling Nav JavaScript -->
  <script src="../lib/js/jquery.easing.min.js"></script>
  <script src="../lib/js/scrolling-nav.js"></script>

</body>

</html>
